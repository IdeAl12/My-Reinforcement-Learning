* numpy & qandas
** 简介及安装
1.运算速度快：numpy和pandas都是采用C编写，pandas又是基于numpy，是numpy的升级版本

2.消耗资源少：采用的是矩阵运算，比python自带的字典或列表快

pip3 install numpy(pandas)

** numpy中的array
*** 创建及属性
   #+BEGIN_SRC python
     import numpy as np
     array = np.array([[1, 2, 3], [2, 3, 4], [4, 5, 6]], dtype=np.float32)
     print(array)
     print("number of dim:", array.ndim)
     print("shape:", array.shape)
     print("size:", array.size)
   #+END_SRC
 
*** 基础运算
**** 1
    #+BEGIN_SRC python
      import numpy as np
      a=np.array([10,20,30,40])   # array([10, 20, 30, 40])
      b=np.arange(4)              # array([0, 1, 2, 3])

      c=a-b  # array([10, 19, 28, 37])
      c=a+b   # array([10, 21, 32, 43])
      c=a*b   # array([  0,  20,  60, 120])
      c=b**2  # 乘方array([0, 1, 4, 9])

      c=10*np.sin(a)  
      # array([-5.44021111,  9.12945251, -9.88031624,  7.4511316 ])

      print(b<3)  
      # array([ True,  True,  True, False], dtype=bool)


    #+END_SRC

**** 2
    #+BEGIN_SRC python
      a=np.array([[1,1],[0,1]])
      b=np.arange(4).reshape((2,2))

      print(a)
      # array([[1, 1],
      #       [0, 1]])

      print(b)
      # array([[0, 1],
      #       [2, 3]])

      # 标准矩阵乘法
      c_dot = np.dot(a,b) # c_dot_2 = a.dot(b)
      # array([[2, 4],
      #       [2, 3]])


    #+END_SRC
**** 3
np.argmin()和np.argmax()两个函数分别对应着求矩阵中最小元素和最大元素的索引。

np.mean()和np.average()计算矩阵中的均值

np.median()求解中位数

np.cumsum()累加函数：生成的每一项元素均是从原矩阵的首项累加到对应项的元素之和。

np.diff()累差函数：每一行中后一项与前一项之差。

np.nonzero()将所有非零元素的行与列坐标分开，重构成两个分别关于行和列的矩阵

np.sort()针对每一行进行从小到大的排序

np.transpose() or a.T 矩阵的转置

np.clip(Array, Array_min, Array_min) 最小值最大值用于让函数判断矩阵中元素是否有比最小值小的或者比最大值大的元素，并将这些指定的元素转换为最小值或者最大值。
*** 索引
**** 一维
A[2]
**** 二维
A[1,1] or A[1][1]

切片操作 A[1, 1:3]

***** 按行打印

#+BEGIN_SRC python
  for row in A:
      print(row)
  """    
  [ 3,  4,  5, 6]
  [ 7,  8,  9, 10]
  [11, 12, 13, 14]
  """
#+END_SRC
***** 按列打印
即对A进行转置，再将得到的矩阵逐行输出即可得到原矩阵的逐列输出。
      #+BEGIN_SRC python
        for column in A.T:
            print(column)
        """  
        [ 3,  7,  11]
        [ 4,  8,  12]
        [ 5,  9,  13]
        [ 6, 10,  14]
        """
      #+END_SRC
***** 迭代输出

      #+BEGIN_SRC python
        import numpy as np
        A = np.arange(3,15).reshape((3,4))
                 
        print(A.flatten())   
        # array([3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])

        for item in A.flat:
            print(item)
            
        # 3
        # 4
        ……
        # 14
      #+END_SRC
flatten是一个展开性质的函数，将多维的矩阵进行展开成1行的数列。而flat是一个迭代器，本身是一个object属性。
*** 合并
**** np.vstack()
vertical stack:上下合并。

#+BEGIN_SRC emacs-lisp
  A = np.array([1,1,1])
  B = np.array([2,2,2])
           
  print(np.vstack((A,B)))    # vertical stack
  """
  [[1,1,1]
   [2,2,2]]
  """
#+END_SRC
**** np.hstack()
horizontal stack:左右合并

#+BEGIN_SRC python
  D = np.hstack((A,B))       # horizontal stack

  print(D)
  # [1,1,1,2,2,2]

#+END_SRC
**** np.newaxis()
可用于转置

#+BEGIN_SRC python
  import numpy as np
  A = np.array([1,1,1])[:,np.newaxis]
  B = np.array([2,2,2])[:,np.newaxis]
           
  C = np.vstack((A,B))   # vertical stack
  D = np.hstack((A,B))   # horizontal stack

  print(D)
  """
  [[1 2]
  [1 2]
  [1 2]]
  """

  print(A.shape,D.shape)
  # (3,1) (3,2)
#+END_SRC

**** np.concatenate()
方便操作多个矩阵或序列.axis参数控制了矩阵的纵向或是横向打印.

#+BEGIN_SRC python
  C = np.concatenate((A,B,B,A),axis=0)

  print(C)
  """
  array([[1],
         [1],
         [1],
         [2],
         [2],
         [2],
         [2],
         [2],
         [2],
         [1],
         [1],
         [1]])
  """

  D = np.concatenate((A,B,B,A),axis=1)

  print(D)
  """
  array([[1, 2, 2, 1],
         [1, 2, 2, 1],
         [1, 2, 2, 1]])
  """
#+END_SRC

* tensorflow 
** placeholder
tf.placeholder(dtype, struct, name)
第一个是要保存的数据的类型，多数为tf.float32，第二个参数是要保存的数据的结构,e.p [1,2]。在session运行阶段，需要给placeholder提供数据，利用feed_dict的字典给placeholder变量提供数据。

[None, 3]表示列为3，行不定
** variable_scopen 和get_variable:

   #+BEGIN_SRC python
     with tf.variable_scope('scope') as scope1:
         weight1 = tf.get_variable('weights', shape=[2,3])
         bias = tf.get_variable('bias', shape=[3])
     # 共享已经定义好的变量：
     with tf.variable_scope('scope', reuse=True) as scope2:
         weight2 =tf.get_variable('weights')

     # 这两个引用名称指向的是同一个内存对象
   #+END_SRC
** tf.Variable 和 tf.get_variable
使用tf.Variable时，如果检测到命名冲突，系统会自己处理。

使用tf.get_variable时，系统不会处理冲突，而会报错。

当需要共享变量的时候，需要使用tf.get_variable。在其他情况下，这两个的用法是一样的。

本质区别：tf.Variable每次都在创建新对象，所有reuse和它并没有关系。对于get_variable,如果已经存在变量对象。就返回这个对象，如果没有不存在对象，就创建一个新的。
** tf.matmul
Multiplies matrix a by matrix b, producing a*b.
** 池化层pooling,全连接层dense和卷积层conv
*** 1.最大池化层max_pooling2d（一般放在卷积层之后）

#+BEGIN_SRC python
  tf.max_pooling2d(
      inputs,
      pool_size,
      strides,
      padding='valid',
      data_format='channels_last',
      name=None
  )
  e.g
  pool1=tf.layers.max_pooling2d(inputs=x, pool_size=[2,2], strides=2)
#+END_SRC
inputs:进行池化的数据。

pool_size:池化的核大小[pool_height, pool_width],如果长宽相等，可直接设置为一个数。

strides:池化的滑动步长，可设置为[1,1]或一个数。

padding:边缘填充，'same'和'valid'选其一，默认为valid。

data_format:输入数据格式，默认为channels_last,即(batch, height, width, channels)
也可以设置为channels_first 对应 (batch, channels, height, width)。
*** 2.均值池化average_pooling2d

#+BEGIN_SRC python
  tf.layers.average_pooling2d(
      inputs,
      pool_size,
      strides,
      padding='valid',
      data_fromat='channels_last',
      name=None
  )
#+END_SRC
*** 3.全连接层dense

#+BEGIN_SRC python
  tf.layers.dense(inputs,
                  units,
                  activation=None,
                  use_bias=True,
                  kernel_initializer=None,
                  bias_initializer=tf.zeros_initializer(),
                  kernal_regularizer=None,
                  bias_regularizer=None,
                  activity_regularizer=None,
                  trainable=True,
                  name=None,
                  reuse=None
  )
  dense1 = tf.layers.dense(inputs=pool3, units=1024, activation=tf.nn.relu)
  dense2= tf.layers.dense(inputs=dense1, units=512, activation=tf.nn.relu)
  logits= tf.layers.dense(inputs=dense2, units=10, activation=None)
#+END_SRC
inputs:输入数据，2维tensor

units:该层的神经单元节点数

activation:激活函数

use_bias:布尔型，是否使用偏执项

kernel_initializer:卷积核的初始化器

kernel_regularizer:卷积核的正则化

trainable:布尔型，该层是否参加训练，为真则变量加入到图集和中

reuse:布尔型，是否重复使用参数
*** 4.卷积层conv

#+BEGIN_SRC python
  tf.nn.conv2d(
      inputs,
      units,
      activation=None,
      use_bias=True,
      kernel_initializer=None,
      bias_initializer=tf.zeros_initializer(),
      kernal_regularizer=None,
      bias_regularizer=None,
      activity_regularizer=None,
      trainable=True,
      name=None,
      reuse=None
  )
  e.g
  conv1 = tf.layers.conv2d(batch_images, 
                           filters=64,
                           kernel_size=7,
                           strides=2,
                           activation=tf.nn.relu,
                           kernel_initializer=tf.TruncatedNormal(stddev=0.01)
                           bias_initializer=tf.Constant(0.1),
                           kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),
                           bias_regularizer=tf.contrib.layers.l2_regularizer(0.003),
                           name='conv1')
#+END_SRC
inputs: 输入数据，4维tensor.

filters: 卷积核个数。

kernel_size:卷积核大小，如[5，5]。如果长宽相等，也可以直接设置为一个数，如kernel_size=5

strides: 卷积过程中的滑动步长，默认为[1,1]. 也可以直接设置为一个数，如strides=2

padding: 边缘填充，'same' 和'valid‘选其一。默认为valid

data_format: 输入数据格式，默认为channels_last ，即 (batch, height, width, channels),也可以设置为channels_first 对应 (batch, channels, height, width).

dilation_rate: 微步长卷积，这个比较复杂一些，请百度.

activation: 激活函数.

use_bias: Boolean型，是否使用偏置项.

kernel_initializer: 卷积核的初始化器.

bias_initializer: 偏置项的初始化器，默认初始化为0.

kernel_regularizer: 卷积核化的正则化，可选.

bias_regularizer: 偏置项的正则化，可选.

activity_regularizer: 输出的正则化函数.

trainable: Boolean型，表明该层的参数是否参与训练。如果为真则变量加入到图集合中 GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).

reuse: Boolean型, 是否重复使用参数.
** 求lost(cost)的几种方法
Cross-Entropy cost funtion(Negatve log-likehood function)
一般在softmax函数之后使用negative log-likehood作为代价函数

#+BEGIN_SRC python
  1.
  y = tf.nn.softmax(tf.matmul(x, W) + b)
  cross_entropy = - tf.reduce_sum(y_*tf.log(y))
  2.
  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits,
                                                          onehot_labels,
                                                          name='xentropy')
  loss = tf.reduce_mean(cross_entropy, name=''xentropy_mean)
  # onehot——labels需要对样本类别标签进行onehot编码

#+END_SRC
* matplotlib
Matlab的语法，python语言，latex的画图质量(还可以使用内嵌的)
** pyplot快速绘图
matplotlib通过pyplot模块提供了一套和MATLAB类似的绘图API，将复杂结构隐藏在API内部，用法简单，但不适合在较大的应用程序中使用。
*** plt.gcf() 
get current figure
*** plt.gca()
get current axes

*** 绘制多子图
常用类的包含关系Figure->Axes->(Line2D, Text, etc.)。一个Figure对象可以包含多个子图(Axes),在matplotlib中使用Axes对象表示一个绘图区域，可理解为子图。

#+BEGIN_SRC python
  subpolt(numRows, numCols, plotNum)
#+END_SRC
subpolt将整个绘图区域等分为numRows行*numCols列个子区域，按照从左到右，从上到下的顺序对每个子区域进行编号。

#+BEGIN_SRC python
  import numpy as np
  import matplotlib.pyplot as plt
   
  plt.figure(1) # 创建图表1
  plt.figure(2) # 创建图表2
  ax1 = plt.subplot(211) # 在图表2中创建子图1
  ax2 = plt.subplot(212) # 在图表2中创建子图2
   
  x = np.linspace(0, 3, 100)
  for i in xrange(5):
      plt.figure(1)  #❶ # 选择图表1
      plt.plot(x, np.exp(i*x/3))
      plt.sca(ax1)   #❷ # 选择图表2的子图1
      plt.plot(x, np.sin(i*x))
      plt.sca(ax2)  # 选择图表2的子图2
      plt.plot(x, np.cos(i*x))
   
  plt.show()

#+END_SRC



** pylab快速绘图
包含了许多numpy和pyplot模块常用的函数，适合在IPython交互式环境中使用。

#+BEGIN_SRC python
  import pylab as pl
#+END_SRC
*** Line and scatter plots
**** line plots 折线图 

     #+BEGIN_SRC python
       import numpy as np
       import pylab as pl
        
       x = [1, 2, 3, 4, 5]# Make an array of x values
       y = [1, 4, 9, 16, 25]# Make an array of y values for each x value
        
       pl.plot(x, y)# use pylab to plot x and y
       pl.show()# show the plot on the screen
     #+END_SRC
**** Scatter  plots 散点图

     #+BEGIN_SRC python
       pl.plot(x, y, 'o')
     #+END_SRC
*** 美化
**** 线条颜色

     #+BEGIN_SRC python
       pl.plot(x, y, 'or')
     #+END_SRC
b(blue);g(green);r(red);c(cyan);m(magenta洋红色);y(yellow);k(black);w(white)
**** 虚线

     #+BEGIN_SRC python
       pl.plot(x,y,'--')
     #+END_SRC
**** marker样式
s(square);p(pentagon);*(star);h(hexagon1六边形);H(hexagon2);

+(plus);x(x marker);D(diamond);d(thin diamond)
**** 图和坐标轴标题以及轴坐标限度plot and axis titles and limits

     #+BEGIN_SRC python
       x = [1, 2, 3, 4, 5]# Make an array of x values
       y = [1, 4, 9, 16, 25]# Make an array of y values for each x value
       pl.plot(x, y)# use pylab to plot x and y
        
       pl.title(’Plot of y vs. x’)# give plot a title
       pl.xlabel(’x axis’)# make axis labels
       pl.ylabel(’y axis’)
        
       pl.xlim(0.0, 7.0)# set axis limits
       pl.ylim(0.0, 30.)
        
       pl.show()# show the plot on the screen
     #+END_SRC
**** 在一个坐标系上绘制多个图

     #+BEGIN_SRC python
       x1 = [1, 2, 3, 4, 5]# Make x, y arrays for each graph
       y1 = [1, 4, 9, 16, 25]
       x2 = [1, 2, 4, 6, 8]
       y2 = [2, 4, 8, 12, 16]
        
       pl.plot(x1, y1, ’r’)# use pylab to plot x and y
       pl.plot(x2, y2, ’g’)
        
       pl.title(’Plot of y vs. x’)# give plot a title
       pl.xlabel(’x axis’)# make axis labels
       pl.ylabel(’y axis’)
        
        
       pl.xlim(0.0, 9.0)# set axis limits
       pl.ylim(0.0, 30.)
     #+END_SRC
**** 图例 Figure legends

     #+BEGIN_SRC python
       pl.legend((plot1, plot2), (’label1, label2’), 'best’, numpoints=1)
     #+END_SRC
第三个参数表示图例放置的位置：best; upper right; upper left; center; lower left; lower right.

如果当前figure里plot的时候已经指定了label，就可以直接调用plt.legend()

#+BEGIN_SRC python
  plt.plot(x,z,label="cos(x^2)")
  plt.legend()
#+END_SRC
常规：

#+BEGIN_SRC python
  pl.legend([plot1, plot2], (’red line’, ’green circles’), ’best’, numpoints=1)# make legend
#+END_SRC
*** Histograms 直方图

    #+BEGIN_SRC python
      import numpy as np
      import pylab as pl
       
      # make an array of random numbers with a gaussian distribution with
      # mean = 5.0
      # rms = 3.0
      # number of points = 1000
      data = np.random.normal(5.0, 3.0, 1000)
       
      # make a histogram of the data array
      pl.hist(data)
      # 若不想要黑色轮廓：
      # pl.hist(data, histtype='stepfilled')
      # make plot labels
      pl.xlabel(’data’)
      pl.show()
    #+END_SRC



*** 对LaTex数学公式的支持
在字符串前后添加$符号，matplotlib就回使用内嵌的latex引擎绘制数学公式
*** 对数坐标轴

    #+BEGIN_SRC python
      ax.semilogx(x,y) #x轴为对数坐标轴
      ax.semilogy(x,y) #y轴为对数坐标轴
      ax.loglog(x,y) #双对数坐标轴
    #+END_SRC
