* numpy & qandas
** 简介及安装
1.运算速度快：numpy和pandas都是采用C编写，pandas又是基于numpy，是numpy的升级版本

2.消耗资源少：采用的是矩阵运算，比python自带的字典或列表快

pip3 install numpy(pandas)

** numpy中的array
*** 创建及属性
   #+BEGIN_SRC python
     import numpy as np
     array = np.array([[1, 2, 3], [2, 3, 4], [4, 5, 6]], dtype=np.float32)
     print(array)
     print("number of dim:", array.ndim)
     print("shape:", array.shape)
     print("size:", array.size)
   #+END_SRC
 
*** 基础运算
**** 1
    #+BEGIN_SRC python
      import numpy as np
      a=np.array([10,20,30,40])   # array([10, 20, 30, 40])
      b=np.arange(4)              # array([0, 1, 2, 3])

      c=a-b  # array([10, 19, 28, 37])
      c=a+b   # array([10, 21, 32, 43])
      c=a*b   # array([  0,  20,  60, 120])
      c=b**2  # 乘方array([0, 1, 4, 9])

      c=10*np.sin(a)  
      # array([-5.44021111,  9.12945251, -9.88031624,  7.4511316 ])

      print(b<3)  
      # array([ True,  True,  True, False], dtype=bool)


    #+END_SRC

**** 2
    #+BEGIN_SRC python
      a=np.array([[1,1],[0,1]])
      b=np.arange(4).reshape((2,2))

      print(a)
      # array([[1, 1],
      #       [0, 1]])

      print(b)
      # array([[0, 1],
      #       [2, 3]])

      # 标准矩阵乘法
      c_dot = np.dot(a,b) # c_dot_2 = a.dot(b)
      # array([[2, 4],
      #       [2, 3]])


    #+END_SRC
**** 3
np.argmin()和np.argmax()两个函数分别对应着求矩阵中最小元素和最大元素的索引。

np.mean()和np.average()计算矩阵中的均值

np.median()求解中位数

np.cumsum()累加函数：生成的每一项元素均是从原矩阵的首项累加到对应项的元素之和。

np.diff()累差函数：每一行中后一项与前一项之差。

np.nonzero()将所有非零元素的行与列坐标分开，重构成两个分别关于行和列的矩阵

np.sort()针对每一行进行从小到大的排序

np.transpose() or a.T 矩阵的转置

np.clip(Array, Array_min, Array_min) 最小值最大值用于让函数判断矩阵中元素是否有比最小值小的或者比最大值大的元素，并将这些指定的元素转换为最小值或者最大值。
*** 索引
**** 一维
A[2]
**** 二维
A[1,1] or A[1][1]

切片操作 A[1, 1:3]

***** 按行打印

#+BEGIN_SRC python
  for row in A:
      print(row)
  """    
  [ 3,  4,  5, 6]
  [ 7,  8,  9, 10]
  [11, 12, 13, 14]
  """
#+END_SRC
***** 按列打印
即对A进行转置，再将得到的矩阵逐行输出即可得到原矩阵的逐列输出。
      #+BEGIN_SRC python
        for column in A.T:
            print(column)
        """  
        [ 3,  7,  11]
        [ 4,  8,  12]
        [ 5,  9,  13]
        [ 6, 10,  14]
        """
      #+END_SRC
***** 迭代输出

      #+BEGIN_SRC python
        import numpy as np
        A = np.arange(3,15).reshape((3,4))
                 
        print(A.flatten())   
        # array([3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])

        for item in A.flat:
            print(item)
            
        # 3
        # 4
        ……
        # 14
      #+END_SRC
flatten是一个展开性质的函数，将多维的矩阵进行展开成1行的数列。而flat是一个迭代器，本身是一个object属性。
*** 合并
**** np.vstack()
vertical stack:上下合并。

#+BEGIN_SRC emacs-lisp
  A = np.array([1,1,1])
  B = np.array([2,2,2])
           
  print(np.vstack((A,B)))    # vertical stack
  """
  [[1,1,1]
   [2,2,2]]
  """
#+END_SRC
**** np.hstack()
horizontal stack:左右合并

#+BEGIN_SRC python
  D = np.hstack((A,B))       # horizontal stack

  print(D)
  # [1,1,1,2,2,2]

#+END_SRC
**** np.newaxis()
可用于转置

#+BEGIN_SRC python
  import numpy as np
  A = np.array([1,1,1])[:,np.newaxis]
  B = np.array([2,2,2])[:,np.newaxis]
           
  C = np.vstack((A,B))   # vertical stack
  D = np.hstack((A,B))   # horizontal stack

  print(D)
  """
  [[1 2]
  [1 2]
  [1 2]]
  """

  print(A.shape,D.shape)
  # (3,1) (3,2)
#+END_SRC

**** np.concatenate()
方便操作多个矩阵或序列.axis参数控制了矩阵的纵向或是横向打印.

#+BEGIN_SRC python
  C = np.concatenate((A,B,B,A),axis=0)

  print(C)
  """
  array([[1],
         [1],
         [1],
         [2],
         [2],
         [2],
         [2],
         [2],
         [2],
         [1],
         [1],
         [1]])
  """

  D = np.concatenate((A,B,B,A),axis=1)

  print(D)
  """
  array([[1, 2, 2, 1],
         [1, 2, 2, 1],
         [1, 2, 2, 1]])
  """
#+END_SRC

* tensorflow 
** placeholder
tf.placeholder(dtype, struct, name)
第一个是要保存的数据的类型，多数为tf.float32，第二个参数是要保存的数据的结构,e.p [1,2]。在session运行阶段，需要给placeholder提供数据，利用feed_dict的字典给placeholder变量提供数据。

[None, 3]表示列为3，行不定
** variable_scopen 和get_variable:

   #+BEGIN_SRC python
     with tf.variable_scope('scope') as scope1:
         weight1 = tf.get_variable('weights', shape=[2,3])
         bias = tf.get_variable('bias', shape=[3])
     # 共享已经定义好的变量：
     with tf.variable_scope('scope', reuse=True) as scope2:
         weight2 =tf.get_variable('weights')

     # 这两个引用名称指向的是同一个内存对象
   #+END_SRC
** tf.Variable 和 tf.get_variable
使用tf.Variable时，如果检测到命名冲突，系统会自己处理。

使用tf.get_variable时，系统不会处理冲突，而会报错。

当需要共享变量的时候，需要使用tf.get_variable。在其他情况下，这两个的用法是一样的。

本质区别：tf.Variable每次都在创建新对象，所有reuse和它并没有关系。对于get_variable,如果已经存在变量对象。就返回这个对象，如果没有不存在对象，就创建一个新的。
** tf.matmul
Multiplies matrix a by matrix b, producing a*b.
** 池化层pooling,全连接层dense和卷积层conv
*** 1.最大池化层max_pooling2d（一般放在卷积层之后）

#+BEGIN_SRC python
  tf.max_pooling2d(
      inputs,
      pool_size,
      strides,
      padding='valid',
      data_format='channels_last',
      name=None
  )
  e.g
  pool1=tf.layers.max_pooling2d(inputs=x, pool_size=[2,2], strides=2)
#+END_SRC
inputs:进行池化的数据。

pool_size:池化的核大小[pool_height, pool_width],如果长宽相等，可直接设置为一个数。

strides:池化的滑动步长，可设置为[1,1]或一个数。

padding:边缘填充，'same'和'valid'选其一，默认为valid。

data_format:输入数据格式，默认为channels_last,即(batch, height, width, channels)
也可以设置为channels_first 对应 (batch, channels, height, width)。
*** 2.均值池化average_pooling2d

#+BEGIN_SRC python
  tf.layers.average_pooling2d(
      inputs,
      pool_size,
      strides,
      padding='valid',
      data_fromat='channels_last',
      name=None
  )
#+END_SRC
*** 3.全连接层dense

#+BEGIN_SRC python
  tf.layers.dense(inputs,
                  units,
                  activation=None,
                  use_bias=True,
                  kernel_initializer=None,
                  bias_initializer=tf.zeros_initializer(),
                  kernal_regularizer=None,
                  bias_regularizer=None,
                  activity_regularizer=None,
                  trainable=True,
                  name=None,
                  reuse=None
  )
  dense1 = tf.layers.dense(inputs=pool3, units=1024, activation=tf.nn.relu)
  dense2= tf.layers.dense(inputs=dense1, units=512, activation=tf.nn.relu)
  logits= tf.layers.dense(inputs=dense2, units=10, activation=None)
#+END_SRC
inputs:输入数据，2维tensor

units:该层的神经单元节点数

activation:激活函数

use_bias:布尔型，是否使用偏执项

kernel_initializer:卷积核的初始化器

kernel_regularizer:卷积核的正则化

trainable:布尔型，该层是否参加训练，为真则变量加入到图集和中

reuse:布尔型，是否重复使用参数
*** 4.卷积层conv

#+BEGIN_SRC python
  tf.nn.conv2d(
      inputs,
      units,
      activation=None,
      use_bias=True,
      kernel_initializer=None,
      bias_initializer=tf.zeros_initializer(),
      kernal_regularizer=None,
      bias_regularizer=None,
      activity_regularizer=None,
      trainable=True,
      name=None,
      reuse=None
  )
  e.g
  conv1 = tf.layers.conv2d(batch_images, 
                           filters=64,
                           kernel_size=7,
                           strides=2,
                           activation=tf.nn.relu,
                           kernel_initializer=tf.TruncatedNormal(stddev=0.01)
                           bias_initializer=tf.Constant(0.1),
                           kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),
                           bias_regularizer=tf.contrib.layers.l2_regularizer(0.003),
                           name='conv1')
#+END_SRC
inputs: 输入数据，4维tensor.

filters: 卷积核个数。

kernel_size:卷积核大小，如[5，5]。如果长宽相等，也可以直接设置为一个数，如kernel_size=5

strides: 卷积过程中的滑动步长，默认为[1,1]. 也可以直接设置为一个数，如strides=2

padding: 边缘填充，'same' 和'valid‘选其一。默认为valid

data_format: 输入数据格式，默认为channels_last ，即 (batch, height, width, channels),也可以设置为channels_first 对应 (batch, channels, height, width).

dilation_rate: 微步长卷积，这个比较复杂一些，请百度.

activation: 激活函数.

use_bias: Boolean型，是否使用偏置项.

kernel_initializer: 卷积核的初始化器.

bias_initializer: 偏置项的初始化器，默认初始化为0.

kernel_regularizer: 卷积核化的正则化，可选.

bias_regularizer: 偏置项的正则化，可选.

activity_regularizer: 输出的正则化函数.

trainable: Boolean型，表明该层的参数是否参与训练。如果为真则变量加入到图集合中 GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).

reuse: Boolean型, 是否重复使用参数.
** 求lost(cost)的几种方法
Cross-Entropy cost funtion(Negatve log-likehood function)
一般在softmax函数之后使用negative log-likehood作为代价函数

#+BEGIN_SRC python
  1.
  y = tf.nn.softmax(tf.matmul(x, W) + b)
  cross_entropy = - tf.reduce_sum(y_*tf.log(y))
  2.
  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits,
                                                          onehot_labels,
                                                          name='xentropy')
  loss = tf.reduce_mean(cross_entropy, name=''xentropy_mean)
  # onehot——labels需要对样本类别标签进行onehot编码

#+END_SRC
* matplotlib
Matlab的语法，python语言，latex的画图质量(还可以使用内嵌的)
** pyplot快速绘图
matplotlib通过pyplot模块提供了一套和MATLAB类似的绘图API，将复杂结构隐藏在API内部，用法简单，但不适合在较大的应用程序中使用。
*** plt.gcf() 
get current figure
*** plt.gca()
get current axes

*** 绘制多子图
常用类的包含关系Figure->Axes->(Line2D, Text, etc.)。一个Figure对象可以包含多个子图(Axes),在matplotlib中使用Axes对象表示一个绘图区域，可理解为子图。

#+BEGIN_SRC python
  subpolt(numRows, numCols, plotNum)
#+END_SRC
subpolt将整个绘图区域等分为numRows行*numCols列个子区域，按照从左到右，从上到下的顺序对每个子区域进行编号。

#+BEGIN_SRC python
  import numpy as np
  import matplotlib.pyplot as plt
   
  plt.figure(1) # 创建图表1
  plt.figure(2) # 创建图表2
  ax1 = plt.subplot(211) # 在图表2中创建子图1
  ax2 = plt.subplot(212) # 在图表2中创建子图2
   
  x = np.linspace(0, 3, 100)
  for i in xrange(5):
      plt.figure(1)  #❶ # 选择图表1
      plt.plot(x, np.exp(i*x/3))
      plt.sca(ax1)   #❷ # 选择图表2的子图1
      plt.plot(x, np.sin(i*x))
      plt.sca(ax2)  # 选择图表2的子图2
      plt.plot(x, np.cos(i*x))
   
  plt.show()

#+END_SRC



** pylab快速绘图
包含了许多numpy和pyplot模块常用的函数，适合在IPython交互式环境中使用。

#+BEGIN_SRC python
  import pylab as pl
#+END_SRC
*** Line and scatter plots
**** line plots 折线图 

     #+BEGIN_SRC python
       import numpy as np
       import pylab as pl
        
       x = [1, 2, 3, 4, 5]# Make an array of x values
       y = [1, 4, 9, 16, 25]# Make an array of y values for each x value
        
       pl.plot(x, y)# use pylab to plot x and y
       pl.show()# show the plot on the screen
     #+END_SRC
**** Scatter  plots 散点图

     #+BEGIN_SRC python
       pl.plot(x, y, 'o')
     #+END_SRC
*** 美化
**** 线条颜色

     #+BEGIN_SRC python
       pl.plot(x, y, 'or')
     #+END_SRC
b(blue);g(green);r(red);c(cyan);m(magenta洋红色);y(yellow);k(black);w(white)
**** 虚线

     #+BEGIN_SRC python
       pl.plot(x,y,'--')
     #+END_SRC
**** marker样式
s(square);p(pentagon);*(star);h(hexagon1六边形);H(hexagon2);

+(plus);x(x marker);D(diamond);d(thin diamond)
**** 图和坐标轴标题以及轴坐标限度plot and axis titles and limits

     #+BEGIN_SRC python
       x = [1, 2, 3, 4, 5]# Make an array of x values
       y = [1, 4, 9, 16, 25]# Make an array of y values for each x value
       pl.plot(x, y)# use pylab to plot x and y
        
       pl.title(’Plot of y vs. x’)# give plot a title
       pl.xlabel(’x axis’)# make axis labels
       pl.ylabel(’y axis’)
        
       pl.xlim(0.0, 7.0)# set axis limits
       pl.ylim(0.0, 30.)
        
       pl.show()# show the plot on the screen
     #+END_SRC
**** 在一个坐标系上绘制多个图

     #+BEGIN_SRC python
       x1 = [1, 2, 3, 4, 5]# Make x, y arrays for each graph
       y1 = [1, 4, 9, 16, 25]
       x2 = [1, 2, 4, 6, 8]
       y2 = [2, 4, 8, 12, 16]
        
       pl.plot(x1, y1, ’r’)# use pylab to plot x and y
       pl.plot(x2, y2, ’g’)
        
       pl.title(’Plot of y vs. x’)# give plot a title
       pl.xlabel(’x axis’)# make axis labels
       pl.ylabel(’y axis’)
        
        
       pl.xlim(0.0, 9.0)# set axis limits
       pl.ylim(0.0, 30.)
     #+END_SRC
**** 图例 Figure legends

     #+BEGIN_SRC python
       pl.legend((plot1, plot2), (’label1, label2’), 'best’, numpoints=1)
     #+END_SRC
第三个参数表示图例放置的位置：best; upper right; upper left; center; lower left; lower right.

如果当前figure里plot的时候已经指定了label，就可以直接调用plt.legend()

#+BEGIN_SRC python
  plt.plot(x,z,label="cos(x^2)")
  plt.legend()
#+END_SRC
常规：

#+BEGIN_SRC python
  pl.legend([plot1, plot2], (’red line’, ’green circles’), ’best’, numpoints=1)# make legend
#+END_SRC
*** Histograms 直方图

    #+BEGIN_SRC python
      import numpy as np
      import pylab as pl
       
      # make an array of random numbers with a gaussian distribution with
      # mean = 5.0
      # rms = 3.0
      # number of points = 1000
      data = np.random.normal(5.0, 3.0, 1000)
       
      # make a histogram of the data array
      pl.hist(data)
      # 若不想要黑色轮廓：
      # pl.hist(data, histtype='stepfilled')
      # make plot labels
      pl.xlabel(’data’)
      pl.show()
    #+END_SRC



*** 对LaTex数学公式的支持
在字符串前后添加$符号，matplotlib就回使用内嵌的latex引擎绘制数学公式
*** 对数坐标轴

    #+BEGIN_SRC python
      ax.semilogx(x,y) #x轴为对数坐标轴
      ax.semilogy(x,y) #y轴为对数坐标轴
      ax.loglog(x,y) #双对数坐标轴
    #+END_SRC
* python
** isinstance
isinstance 是Python中的一个内建函数，用来判断一个对象的变量类型。
语法：

#+BEGIN_SRC python
  isinstance(object, classinfo)
#+END_SRC

如果参数object是classinfo的实例，或者object是classinfo类的子类的一个实例，返回true。
** assert
assert断言是声明其布尔值必须为真的判定，如果发生异常说明表达式为假
语法：

#+BEGIN_SRC python
  assert expression

#+END_SRC

等价于：
 #+BEGIN_SRC python
    if not expression:
        raise AssertionError
  #+END_SRC

* Theano
** Why theano?
1. tensowflow目前只能在MacOS和Linux，theano还可以在Windows下运行。
2. theano可以使用GPU进行运算，用GPU比CPU快100倍左右。
3. tensowflow比较商业化，theano比较学术性
** 基本用法

   #+BEGIN_SRC python
     import numpy as np
     import theano.rensor as T
     from theano import function
     #定义X和Y两个常量scalar，结构建立好后，把结构放在function，再把数据放在function
     #basic
     x = T.dscalar('x') #建立x的容器
     y = T.dscalar('y') #建立y的容器
     z = x + y #建立方程

     # 使用function定义theano的方程
     # 将输入值x，y放在[]里，输出值z放在后面
     f = funxtion([x, y], z)

     print(f(2, 3))

   #+END_SRC

使用theano中的pp(pretty-print)可以打印出原始方程


#+BEGIN_SRC python
  from theano import pp
  print(pp(z))
  # (x + y)
#+END_SRC

定义矩阵，以及利用矩阵做相关的运算


#+BEGIN_SRC python
  x = T.dmatrix('x')  # 矩阵 x 的容器
  y = T.dmatrix('y')  # 矩阵 y 的容器
  z = x + y   # 定义矩阵加法
  f = function([x, y], z) # 定义方程

  print(f(
      np.arange(12).reshape((3,4)),
      10*np.ones((3,4))
  )
  )
  """
  [[ 10.  11.  12.  13.]
   [ 14.  15.  16.  17.]
   [ 18.  19.  20.  21.]]
  """
#+END_SRC
** Function用法
首先导入所需要的python包：

#+BEGIN_SRC python
  import numpy as np
  import theano.tensor as T
  import theano
#+END_SRC

*** 激励函数例子activation function

    #+BEGIN_SRC python
      #首先定义一个tensor T：
      x = T.dmatrix('x')

      #然后声明概率计算方式，要用theano里的计算方式，不能使用numpy里的
      s = 1/(1+T.exp(-x))

      #最后调用theeano定义的计算函数logistic
      logistic = theano.function([x], s)
      print(logistic([0, 1], [-2, -3]))
      """
      [[ 0.5         0.73105858]
       [ 0.26894142  0.11920292]]
      """
    #+END_SRC

*** 多输入/输出的function

    #+BEGIN_SRC python
      #假定输入和输出是两个，指定输入的值是矩阵a，b
      a,b = T.dmatrics('a', 'b')

      #diff:差； abs_diff:差的绝对值； diff_squared：差的平方
      diff = a-b
      abs_diff = abs(diff)
      diff_squared = diff**2

      #在这次使用theano.function的时候可以指定两个输，并且输出这两个数值的差（diff），差的绝对值（abs_diff）， 差的平方（diff_squared）。当我们在调用这个函数的时候会将这三个结果作为输出值。
      f = theano.function([a, b], [diff, abs_diff, diff_squared])

      x1,x2,x3= f(
          np.ones((2,2)), # a
          np.arange(4).reshape((2,2))  # b
      )
      print(x1, x2, x3)

      """
      array([[ 1.,  0.],
             [-1., -2.]]),
      array([[ 1.,  0.],
             [ 1.,  2.]]),
      array([[ 1.,  0.],

             [ 1.,  4.]])
      """
    #+END_SRC

*** function的名字

    #+BEGIN_SRC python
      #首先定义三个纯量的容器，以及输出值z
      x,y,w = T.dscalars('x','y','w')
      z = (x+y)*w

      #默认值的书写方式：
      f = theano.function([x,
                           theano.In(y, value=1),
                           theano.In(w,value=2)],
                          z)

      print(f(23))    # 使用默认
      print(f(23,1,4)) # 不使用默认
      """
      48.0
      100.0
      """

      #指定参数的名字：
      f = theano.function([x,
                           theano.In(y, value=1),
                           theano.In(w,value=2,name='weights')],
                          z)

      print (f(23,1,weights=4)) ##调用方式

      """
      100.0
      """
    #+END_SRC
** Shared变量
Shared变量：这些变量可以在运算过程中，不停地进行交换和更新。在定义weights和bias时需要用到
*** 定义

    #+BEGIN_SRC python
      state = theano.shared(np.array(0, dtype = np.float64), 'state')#inital state = 0
    #+END_SRC
要用np.array赋初值，初始值是0，并且要规定好数据类型。
数据类型很重要，在后面定义vector或matrix的时候，一定要统一。


#+BEGIN_SRC python
  #下面是累加值，定义它的名字为 inc，还有它的数据类型，调用 state.dtype，而不是写 dtype=np.float64， 否则会报错。
  inc = T.scalar('inc', dtype=state.dtype)

  #接下来是要定义一个 accumulator 函数，它的输入参数为 inc，结果就是输出 state，累加的过程叫做 updates，就是要把现在的 state 变成 state+inc 。
  accumulator = theano.function([inc], state, updates=[(state, state+inc)])
#+END_SRC

*** 提取使用
打印不能直接使用print(accumulator(10)),这样输入的，第一次就是初始值0，下一次输出的时候才能输出10.

#+BEGIN_SRC python
  # to get variable value
  print(state.get_value())
  # 0.0

  accumulator(1)   # return previous value, 0 in here
  print(state.get_value())
  # 1.0

  accumulator(10)  # return previous value, 1 in here
  print(state.get_value())
  # 11.0
  #get_value可以用来提取参数的值
  #set_value可以用来重新设置参数
  #get_value和set_value只能在share变量的时候调用
#+END_SRC
