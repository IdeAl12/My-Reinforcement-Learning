* Google机器学习速成课程
** 框架处理
*** 监督式学习
机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。
*** 基本术语
**** 标签
在简单线性回归中，标签是我们要预测的事物，即 y 变量。
**** 特征
在简单线性回归中，特征是输入变量，即 x 变量。
**** 样本
样本实质数据的特定实例： *x* (粗体表示矢量)

将样本分为以下两类：

   *有标签样本：同时包含特征和标签，即：
  labeled examples: {features, label}: (x, y)

   *无标签样本 ：包含特征，但不包含标签，即：
  unlabeled examples: {features, ?}: (x, ?)
**** 模型
模型定义了特征与标签之间的关系。两个阶段：
***** 训练
表示创建或学习模型，向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。
***** 推断
表示将训练后的模型应用于无标签样本。
**** 回归于分类
回归模型课预测连续值。

分类模型课预测离散值。
** 降低损失(Reducing Loss):随机梯度下降法(SGD)
在梯度下降法中，批量指的是用于在单词迭代中计算梯度的样本总数。如果是超大批量，则单次迭代就可能要花很长时间进行计算。

包含随机抽样样本的大型数据及可能包含荣誉数据。实际上，批量大小越大，出现荣誉的可能性越高。一些荣誉可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。

“随机”表示构成各个批量的一个样本都是随机选择的。。SGD每次迭代只使用一个样本。小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。
